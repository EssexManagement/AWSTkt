#!/bin/bash -f

### This script will create a TAR file, if `TarCmd` (a.k.a. CLI-arg #1) is the string "True" (initial upper-case letter)

if [ $# != 5 ]; then
    echo "Usage: $0 <Tier> <TarCmd> <subProjFolderPath> <whether2UseAdvancedCaching> <CodePipelineS3BktName>"
    exit 1
fi

### ----------- define CONSTANTS -----------

Tier="$1"
TarCmd="$2"
subProjFolderPath="$3"
whether2UseAdvancedCaching="$4"
CodePipelineS3BktName="$5"
echo "Tier = '${Tier}'"
echo "TarCmd = '${TarCmd}'"
echo "subProjFolderPath = '${subProjFolderPath}'"
echo "whether2UseAdvancedCaching = '${whether2UseAdvancedCaching}'"
echo "CodePipelineS3BktName = '${CodePipelineS3BktName}'"


ENTERPRISE_NAME="NIH-NCI"
CDKAppName="FACT"
ComponentName="backend"

MaxCacheAge=30 ### hours

CodeBuild_FileCacheFldr="tmp/CodeBuild_FileCacheFldr"
    ### !! ATTENTION !! This ABOVE variable --MUST-- remain identical to the Python-variable inside `common/cdk/constants_cdk.py`
    ### CodeBuild only caches Folders. So, files-to-be-cached have to be put into a folder!
Fldrs2bArchivedBeforeCaching=(  .venv   node_modules )
    ### These 2 folders will be converted into ARCHIVE-FILES (tar-files to be specific).  These ARCHIVE-files will theb be cached as per variable above.

### ----------- Derived -----------

if [ ${subProjFolderPath} == "." ]; then
    InitialS3Prefix="${ENTERPRISE_NAME}/${CDKAppName}/${ComponentName}/${Tier}"
else
    InitialS3Prefix="${ENTERPRISE_NAME}/${CDKAppName}/${ComponentName}/${Tier}/${subProjFolderPath}"
fi
echo "InitialS3Prefix = '${InitialS3Prefix}'"

if [ ${OSTYPE} == "darwin24" ]; then
    AWSPROFILEREGION=( --profile "${AWSPROFILE}" --region "${AWSREGION}" )
else
    AWSPROFILEREGION=""
fi
echo "AWSPROFILEREGION = '${AWSPROFILEREGION[@]}'"

### ----------- Validate CLI-args -----------

if [ "${TarCmd}" != "create-tar" ] && [ "${TarCmd}" != "un-tar" ]; then
    echo "ERROR: 1st CLI-arg must be either 'create-tar' or 'un-tar'"
    exit 1
fi
if [ "${whether2UseAdvancedCaching}" != "True" ] && [ "${whether2UseAdvancedCaching}" != "False" ]; then
    echo "ERROR: 3rd CLI-arg must be either 'True' or 'False'"
    exit 1
fi

echo "Within script $0 .. .."
echo "  TarCmd = '${TarCmd}'"
echo "  subProjFolderPath = '${subProjFolderPath}'"
echo "  whether2UseAdvancedCaching = '${whether2UseAdvancedCaching}'"

if [ "${whether2UseAdvancedCaching}" == "False" ]; then
    echo "--NO-- advanced-caching (for node_modules and python's-venv)"
    exit 0
fi

### ----------- DEBUG-output -----------

pwd
# ls -la
printf '%.0s^' {1..40}; echo ''
ls -la ./tmp/.
printf '%.0s.' {1..40}; echo ''
mkdir -p ./${CodeBuild_FileCacheFldr}/   ### We need this, else .. (For the 1st time) a lot of code below will fail to create/read files under this.
ls -la ./${CodeBuild_FileCacheFldr}/
printf '%.0s_' {1..40}; echo ''

realPath=$( readlink ./${CodeBuild_FileCacheFldr}/node_modules.tar )
echo "(Sanity-Check/SAMPLE) realPath='${realPath}'"
if [ "${realPath}x" == "x" ]; then
    echo "Sanity-Check: the readlink command returned empty.  So, this must be a plain-file"
    ls -la ./${CodeBuild_FileCacheFldr}/node_modules.tar
else
    ls -la "${realPath}"
fi

### ----------- utility/tools -----------


### This function's return-values: '1' == Logical-True (a.k.a. Too-old), while '0' is Logical-False.
isFileTooOld() {
    myFilePath="$1"
    CodePipelineS3BktName="$2"
    echo "checking if ..../${myFilePath} is more than ${MaxCacheAge} old (Bkt = ${CodePipelineS3BktName}).."

    FullS3ObjectKey="${InitialS3Prefix}/${myFilePath}"
    echo "isFileTooOld(): FullS3ObjectKey = '${FullS3ObjectKey}'"
    FullS3ObjectKey=$( echo $FullS3ObjectKey | sed -e 's|\./||g' | sed -e 's|//||g' )
    echo "isFileTooOld(): FullS3ObjectKey (Final) = '${FullS3ObjectKey}'"

    # if ${myFilePath} does NOT exist, return 1/True (so that it will be re-created/updated)
    # [ ! -f "${myFilePath}" ] && return 1
    # AgeOfCachedFile=$(find "${myFilePath}" -maxdepth 0 -mtime +1);
    # if [ "${AgeOfCachedFile}" == "${myFilePath}" ]; .. ..

    ResponseJson=$( aws s3api get-object-tagging \
        --bucket "${CodePipelineS3BktName}" \
        --key "${FullS3ObjectKey}" \
        ${AWSPROFILEREGION[@]}
    )
    if [ $? -ne 0 ]; then
        echo "isFileTooOld(): Error getting Object's-Tag at s3://${CodePipelineS3BktName}/${FullS3ObjectKey}"
        return 1
    fi
    echo "ResponseJson = ${ResponseJson}"
    FileTimeStamp=$( echo "${ResponseJson}" | jq -r '.TagSet[] | select(.Key=="CreatedBy-DevOps-Pipeline").Value' )
    echo "FileTimeStamp = '${FileTimeStamp}'"  ### This is # of secs since Epoch (generated by `date +%s` cli-cmd)
    NowTime=$(date +%s)
    RunTime=$(( NowTime - FileTimeStamp ))
    echo "RunTime = '${RunTime}'"
    AgeOfCachedFile=$(( RunTime / 3600 ))  ### Convert to # of hours
    echo "AgeOfCachedFile='${AgeOfCachedFile}'"
    if [ "${AgeOfCachedFile}" -gt ${MaxCacheAge}  ]; then
        echo "isFileTooOld(): ..../${myFilePath} is -OLDER- than ${MaxCacheAge} hours!";
        return 1
    else
        echo "isFileTooOld(): ..../${myFilePath} is fresh ( LESS-than 24h old)";
        return 0
    fi
}

### ----------

uploadAndTagNewS3Obj() {
    myFilePath="$1"
    CodePipelineS3BktName="$2"

    FullS3ObjectKey="${InitialS3Prefix}/${myFilePath}"
    echo "uploadAndTagNewS3Obj(): FullS3ObjectKey = '${FullS3ObjectKey}'"
    FullS3ObjectKey=$( echo $FullS3ObjectKey | sed -e 's|\./||g' | sed -e 's|//||g' )
    echo "uploadAndTagNewS3Obj(): FullS3ObjectKey (Final) = '${FullS3ObjectKey}'"

    ### Upload and then Tag the s3-object.
    aws s3 cp ${myFilePath} s3://${CodePipelineS3BktName}/${FullS3ObjectKey} ;

    TIMESTAMP=$(date +%s)
    echo "Tagging S3-object w/ TIMESTAMP = '${TIMESTAMP}'"
    aws s3api put-object-tagging \
        --bucket "${CodePipelineS3BktName}" \
        --key "${FullS3ObjectKey}" \
        --tagging "TagSet=[{Key=CreatedBy-DevOps-Pipeline,Value=${TIMESTAMP}}]" \
        ${AWSPROFILEREGION[@]}
    if [ $? -ne 0 ]; then
        echo "uploadAndTagNewS3Obj(): Error setting tag on s3://${CodePipelineS3BktName}/${FullS3ObjectKey}"
        exit 57
    fi
}

### ------- create tarfile or untar (for the cached-folder within CodeBuild) -----------

for ddd in ${Fldrs2bArchivedBeforeCaching[@]}; do
    echo "------------ ddd = '${ddd}' --------------"
    realPath=$( readlink ./${CodeBuild_FileCacheFldr}/${ddd}.tar )
    echo "realPath='${realPath}'"
    date
    myFilePath="./${CodeBuild_FileCacheFldr}/${ddd}.tar"
    FullS3ObjectKey="${InitialS3Prefix}/${myFilePath}"
    echo "41: FullS3ObjectKey = '${FullS3ObjectKey}'"
    FullS3ObjectKey=$( echo $FullS3ObjectKey | sed -e 's|\./||g' | sed -e 's|//||g' )
    echo "42: FullS3ObjectKey (Final) = '${FullS3ObjectKey}'"

    if [ "${TarCmd}" == "create-tar" ]; then

        if [ "${realPath}x" == "x" ]; then
            ### Symbolic-Link does -NOT- exist.  But, the file "ddd" itself may be a REAL but simple file
            (   cd ${subProjFolderPath}/ ;
                isFileTooOld ${myFilePath} ${CodePipelineS3BktName}
                if [ $? -eq 1 ]; then
                    pwd; echo "Updating ..../${myFilePath} .. ";
                    tar -cf ${myFilePath} ./${ddd} ;
                    uploadAndTagNewS3Obj ${myFilePath} ${CodePipelineS3BktName} ;
                fi
            )
        else
            ### file exists, so .. write to the exact-location where the SYMLINK is.
            (   cd ${subProjFolderPath}/ ;
                isFileTooOld ${myFilePath} ${CodePipelineS3BktName}
                if [ $? -eq 1 ]; then
                    pwd; echo "Updating ..../${myFilePath} .. ";
                    tar -cf $( readlink "${myFilePath}" ) ./${ddd} ;   ### use readlink to decode Linux-SymLink
                    uploadAndTagNewS3Obj ${myFilePath} ${CodePipelineS3BktName} ;
                fi
            )
        fi

    else  ### un-tar / extract-from-archive

        if [ "${realPath}x" == "x" ]; then
            ### Symbolic-Link does -NOT- exist.  But, the file "ddd" itself may be a REAL but simple file
            (   cd ${subProjFolderPath}/ ;
                aws s3 cp s3://${CodePipelineS3BktName}/${FullS3ObjectKey} ${myFilePath} ;   ### Download
                tar -xf "${myFilePath}" ; ### will create ${subProjFolderPath}/${ddd}/
            )
        else
            (   cd ${subProjFolderPath}/ ;
                aws s3 cp s3://${CodePipelineS3BktName}/${FullS3ObjectKey} ${myFilePath} ;   ### Download
                tar -xf $( readlink "${myFilePath}" ) ; ### will create ${subProjFolderPath}/${ddd}/  .. use readlink to decode Linux-SymLink
            )
        fi
    fi
    date
done

printf '%.0s.' {1..40}; echo ''
pwd
ls -la ./${CodeBuild_FileCacheFldr}/
printf '%.0s_' {1..40}; echo ''

### EoF
